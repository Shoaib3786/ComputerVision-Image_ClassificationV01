{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5155f75",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8366163",
   "metadata": {},
   "source": [
    "### Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd8d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 23:33:47.480829: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 23:33:47.888395: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-09 23:33:47.888463: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-09 23:33:49.632204: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 23:33:49.632432: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 23:33:49.632440: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.datasets as dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912f7cb",
   "metadata": {},
   "source": [
    "## Model Building:\n",
    "\n",
    " - Using Model Subclassing API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52a35dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelBuild(Model):\n",
    "    \n",
    "    def __init__(self, num_classCateg):\n",
    "        super().__init__()\n",
    "        \n",
    "        #block-01\n",
    "        self.conv_01 = layers.Conv2D(filters=42,kernel_size=(5,5), activation='relu',padding='same')\n",
    "        self.maxpool_01 = layers.MaxPool2D(pool_size=(2,2), padding='same')\n",
    "        self.batchNorm_01 = layers.BatchNormalization(axis=1)\n",
    "\n",
    "        #block-02\n",
    "        self.conv_02 = layers.Conv2D(filters=50,kernel_size=(3,3), activation='relu', padding='same')\n",
    "        self.maxpool_02 = layers.MaxPool2D(pool_size=(2,2), padding='same')\n",
    "        self.batchNorm_02 = layers.BatchNormalization(axis=1)\n",
    "\n",
    "        #block-03\n",
    "        self.conv_03 = layers.Conv2D(filters=35,kernel_size=(3,3), activation='relu', padding='same')\n",
    "        self.maxpool_03 = layers.GlobalAvgPool2D()\n",
    "        self.batchNorm_03 = layers.BatchNormalization(axis=1)\n",
    "\n",
    "        #Flatten\n",
    "        self.flatten = layers.Flatten()\n",
    "\n",
    "        #block-04\n",
    "        self.dense_01 = layers.Dense(units=60, activation='relu')\n",
    "        self.batchNorm_04 = layers.BatchNormalization(axis=1)\n",
    "        \n",
    "        #block-05\n",
    "        self.dense_02 = layers.Dense(units=65, activation='relu')\n",
    "        self.batchNorm_05 = layers.BatchNormalization(axis=1)\n",
    "        \n",
    "        #Ouput\n",
    "        self.ouput = layers.Dense(num_classCateg, activation='softmax')\n",
    "\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = inputs\n",
    "        \n",
    "        #block_01\n",
    "        x = self.conv_01(x)\n",
    "        x = self.maxpool_01(x)\n",
    "        x = self.batchNorm_01(x)  \n",
    "        #block_02\n",
    "        x = self.conv_02(x) \n",
    "        x = self.maxpool_02(x)\n",
    "        x = self.batchNorm_02(x)\n",
    "        #block_03\n",
    "        x = self.conv_03(x)\n",
    "        x = self.maxpool_02(x)\n",
    "        x = self.batchNorm_03(x)\n",
    "        \n",
    "        #flatten\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        #block_04\n",
    "        x = self.dense_01(x)\n",
    "        x = self.batchNorm_04(x)\n",
    "        #block_05\n",
    "        x = self.dense_02(x)\n",
    "        x = self.batchNorm_05(x)\n",
    "        \n",
    "        #output\n",
    "        return Model()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14aea7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d7a4de0",
   "metadata": {},
   "source": [
    "### Importing Image Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6993bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = dataset.cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = img_data.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9b762",
   "metadata": {},
   "source": [
    "### Important Manipulation of dimensions & Dtype of input data & Normalizing the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87b5255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#increase the dims of x_train, x_test from 3D to 4D as model accepts 4D input data\n",
    "# x_train = np.expand_dims(x_train, axis=3)\n",
    "# x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "\n",
    "# datatype earlier was uint9 which doesn't accepted by the model hence have to typecast it \n",
    "# TYPE CASTED THE DATA AS WELL AS NORMALIZED ITS VALUE\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2c8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4345c76",
   "metadata": {},
   "source": [
    "### CNN model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "876bbbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 00:45:00.796017: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 614400000 exceeds 10% of free system memory.\n",
      "/home/shoaib/anaconda3/lib/python3.9/site-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 59s 37ms/step - loss: 1.5043 - accuracy: 0.4593 - val_loss: 1.3642 - val_accuracy: 0.5211\n",
      "Epoch 2/4\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 1.1375 - accuracy: 0.5972 - val_loss: 1.0550 - val_accuracy: 0.6212\n",
      "Epoch 3/4\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 1.0005 - accuracy: 0.6480 - val_loss: 1.2658 - val_accuracy: 0.5830\n",
      "Epoch 4/4\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.9215 - accuracy: 0.6754 - val_loss: 1.4499 - val_accuracy: 0.5424\n",
      "Model: \"model_build_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           multiple                  3192      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  multiple                 64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          multiple                  18950     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  multiple                 32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          multiple                  15785     \n",
      "                                                                 \n",
      " global_average_pooling2d_1   multiple                 0 (unused)\n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  multiple                 16        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  33660     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  multiple                 240       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  3965      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  multiple                 260       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  660       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76,824\n",
      "Trainable params: 76,518\n",
      "Non-trainable params: 306\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = modelBuild(10)\n",
    "\n",
    "# compile (Backpropogation)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fit\n",
    "model.fit(x_train, y_train, epochs=4,\n",
    "                    validation_data=(x_test, y_test))  # validation data -> dataset for testing the model \n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b117678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictModel(model, x_test):\n",
    "    \n",
    "    class_name = {0:'airplane', 1:'automobile', 2:'bird', \n",
    "              3:'cat', 4:'deer', 5:'dog', 6:'frog', \n",
    "              7:'horse', 8:'ship', 9:\"truck\"}\n",
    "\n",
    "    # taking random value/image from x_test\n",
    "    x = np.random.randint(0,len(x_test))\n",
    "    \n",
    "    # predicting random image probability belonging to which class \n",
    "    prob = model.predict(x_test[x,:].reshape(1,32,32,3))\n",
    "    \n",
    "    # considering max probabilty value\n",
    "    max_prob = np.argmax(prob)\n",
    "    \n",
    "    # Mapping the max probablity with the dictinary of the dataset class\n",
    "    predImage =  class_name.get(max_prob)\n",
    "    \n",
    "    # for making cross checking easier\n",
    "    plt.imshow(x_test[x,:])\n",
    "    print(prob)\n",
    "    print(max_prob)\n",
    "    \n",
    "    return predImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7cbf267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[5.1763898e-04 9.9301285e-01 4.0386748e-04 5.9048616e-04 4.5253943e-05\n",
      "  4.6760216e-04 2.4131787e-04 2.6604816e-05 7.4753293e-04 3.9469609e-03]]\n",
      "1\n",
      "\n",
      "\n",
      "IMAGE: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calling the predictModel\n",
    "predVal = predictModel(model, x_test)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"IMAGE:\",predVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62230aa",
   "metadata": {},
   "source": [
    "### Save trained model;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce355b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# To save your trained model:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN_03_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# To save your trained model:\n",
    "model.save('CNN_03_model')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6bcf6b",
   "metadata": {},
   "source": [
    "### load model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load a model back in memory from an unzipped model folder:\n",
    "\n",
    "model = tf.keras.models.load_model('CNN_03_model')\n",
    "\n",
    "\n",
    "#now do ur predictions\n",
    "model.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
